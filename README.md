# ðŸ§  Prompt Evaluation for B2C Travel Domain

This project evaluates three different **prompt types** â€” Direct, Conversational, and Contextual â€” for their effectiveness in generating high-quality responses from an LLM (GPT-4o). The focus is on the **B2C travel domain**, where accurate, helpful, and engaging responses are critical for user experience.

## ðŸ“Š Project Overview

- **Model Used**: GPT-4o (via ChatGPT)
- **Prompt Types**: Direct, Conversational, Contextual
- **Evaluation Metrics**:
  - Business Contextual Fit
  - User Intent Coverage
  - Tone, Voice & Readability
  - Structured Utility
  - Creativity & Emotional Value
  - Factual Relevance
  - Actionability & Value Add
- **Total Score**: 0â€“21 (sum of all 7 rubric dimensions)

---

## ðŸ“ˆ Key Insights

- **Contextual prompts** performed best overall, especially in structure and factuality.
- **Conversational prompts** excelled in tone but showed variability.
- **Direct prompts** were consistent and fact-focused but lacked creative value.

ðŸ“Œ *Creativity appears inversely related to factual accuracy.*

---

ðŸ”— **Interactive Graphs**: [Click here to explore](https://chitranpande.github.io/prompt-evaluation-b2c-travel/)
